cut -f8 ID_1A.tsv |sort|uniq -c | head | cut -d '|' -f3
cut -f8 ID_1A.tsv |sort|uniq -c > 1a.tsv

 awk -F"\t" '$10<0.01 { print $8 }' ID_1A.tsv |awk -F, '!z[$1]++{ a[$1]=$0; } END {for (i in a) printf("%s\t%s\n",a[i], z[i])}'>ID_1A_fil.tsv

awk -F"\t" '{if(NR==1){print} else if($12<0.01) { print }}'| cat SkylineIntensities_unique.tsv >filtered_intensities.tsv

awk -F"\t" '{if(NR==1){print} else if(match($12,"NA")==0) { print $12 }}' SkylineIntensities_unique.tsv>inter.tsv

awk -F"\t" '{if(NR==1){print} else if(sprintf("%.8f",$12)<0.01) { print }}' inter.tsv >filtered_intensities.tsv



dataProcess(a, logTrans=2, normalization="equalizeMedians",nameStandards=NULL, betweenRunInterferenceScore=FALSE,fillIncompleteRows=FALSE,FeatureSelection=FALSE,lambda=seq(0,1.4,0.1),eta=0.05, address="")	


sed -i 's/original/new/g' file.txt

sed -i 's/\(\[\d*\]\)/''/g' t1.tsv

sed -i 's/\(\[[0-9]*\]\)//g' ID_1A_qfilt.tsv

awk -F"\t" '!seen[$2]++' ID_1A_qfilt.tsv > 1A_q_dupRem.tsv

awk -F"\t" '{print $8}' 1A_q_dupRem.tsv|awk -F, '!z[$1]++{a[$1]=$0;} END { for (i in a) printf("%s\t%s\n", a[i], z[i])}'>1A_countObserved.tsv


Step 1
Filter

 awk -F"\t" '{if(NR==1){print} else if(sprintf("%.8f",$10)<0.01) { print }}' ID_1A.tsv > ID_1A_qfilt.tsv

Step 2
Remove [0-9] oxidation/methylation sites in peptides

sed -i 's/\(\[[0-9]*\]\)//g' ID_1A_qfilt.tsv

Step3
remove duplicates

awk -F"\t" '!seen[$2]++' ID_1A_qfilt.tsv > 1A_q_dupRem.tsv

Step 4
Count Observed peptides

awk -F"\t" '{print $8}' 1A_q_dupRem.tsv|awk -F, '!z[$1]++{a[$1]=$0;} END { for (i in a) printf("%s\t%s\n", a[i], z[i])}'>1A_countObserved.tsv


Step 5
Calculate empai for each replicate in each run

run 
python empai

Step 6
Calculate average empai for each run

python avgEmpai 
